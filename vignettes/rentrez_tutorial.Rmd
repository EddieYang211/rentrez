---
title: Rentrez Tutorial
author: "David winter"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: readable
    figwidth: 3
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
```{r, count_recs, echo=FALSE}
library(rentrez)
count_recs <- function(db, denom) {
    nrecs <-  rentrez::entrez_db_summary(db)["Count"]
    round(as.integer(nrecs)/denom, 1)
}
```
## Introduction: The NCBI, entrez and `rentrez`.

The NCBI stores a _lot_ of data. At the time this document was compiled, there
were `r count_recs("pubmed",1e6)` million papers in [pubmed](http://www.ncbi.nlm.nih.gov/pubmed/),
including `r count_recs("pmc", 1e6)` million full-text records avaliable in [pubmed-central](http://www.ncbi.nlm.nih.gov/pubmed/).
[The NCBI Nucleotide Database](http://www.ncbi.nlm.nih.gov/nuccore) (also known as GenBank) has data for `r count_recs("nuccore", 1e6)`
million different sequences, and [dbSNP](http://www.ncbi.nlm.nih.gov/snp/) describes
`r count_recs("snp", 1e6)` million different genetic variants. All of these
records can be cross-referenced with the  `r floor(as.integer(entrez_search(db="taxonomy", term='species[RANK]')$count)/1000)` thousand
species in the [NCBI taxonomy](www.ncbi.nlm.nih.gov/taxonomy) or `r count_recs("omim", 1e3)` thousand diseases
described in [OMIM]('http://www.ncbi.nlm.nih.gov/omim').


The NCBI makes this data avaliable through a [web interface](http://www.ncbi.nlm.nih.gov/),
an [FTP server](ftp://ftp.ncbi.nlm.nih.gov/) and through a REST API called the
[Entrez Utilities](http://www.ncbi.nlm.nih.gov/books/NBK25500/) (`Eutils` for
short). This package provides functions to wrap that API, allowing users to
gather and combine data from multiple NCBI databases in the confort of a R
session or script.

## Getting started with the rentrez

`rentrez` gives you a few tools that help you to get to know your way around the
NCBI's databases. First, you can use `entrez_dbs()` to find out just what
databases are avaliable:

```{r, dbs}
entrez_dbs()
```

You can find out a bit more about each of those database using a set of
functions with names starting `entrez_db_`:

**Functions that help you learn about NCBI databases**

| Function name            | Return                                               |
|--------------------------|------------------------------------------------------|
| `entrez_db_summary()`    | Brief description of what the database is            |
| `entrez_db_searchable()` | Set of search terms that can used with this database |
| `entrez_db_links() `     | Set of databases that might contain linked records   |

For instance, we can find out a little more about the cryptically named
database 'cdd'...

```{r, cdd}
entrez_db_summary("cdd")
```

... or find out which search terms can be used with the Short Read Archive (SRA)
sequencing database:

```{r, sra_eg}
entrez_db_searchable("sra")
```

Just how these 'helper' functions might help you will become clearer once
you've started using the EUtils api, so let's get started.

## Searching databases: `entrez_search()`

The function `entrez_search()` lets you search for records in a given NCBI
database.  In the simplest case you just need to provide a database name (`db`)
and a search term(`term`).If you print the returned object you get a summary of what it contains, an
d the way the NCBI's servers translated your query:

```{r eg_search}
r_search <- entrez_search(db="pubmed", term="R Language")
r_search
```

There are a few things to note here. First, the NCBI's server has worked out
that we meant R as a programming language, and so inlcuded the
['MeSh' term](http://www.ncbi.nlm.nih.gov/mesh). We'll worry about these and
other special search terms in a second. Second, there are many more 'hits' for this search than there
are unique IDs contained in this object. That's because the optional argument
`retmax`, which controls the maximum number of returned values has a default
value of 20. We can acess those 20 IDs like this:


```{r search_ids}
r_search$ids
```

And get more IDs by increasing the `ret_max` argument.

```{r searchids_2}
another_r_search <- entrez_search(db="pubmed", term="R Language", retmax=40)
another_r_search
```

If we want to get IDs for all of those thousands of records that match this
search, we can use the NCBI's web history feature, DESCRIBED LATER IN THE
TUTORIAL


### Building search terms

The EUtils api uses a special syntax to build search queries. You can search a
database against a specific term using the format `query[SEARCH TERM]`, and
combine multiple such seaches using the operators `AND`, `OR` and `NOT`.

For instance, we can find next generation sequence datasets for the (amazing...) ciliate
_Tetrahymena thermophila_ by using the organism ('ORGN') search field:


```{r, Tt}
entrez_search(db="sra",
              term="Tetrahymena thermophila[ORGN]",
              retmax=0)
```

Find only those records that have been added recently (using the colon to
sepcify a range of values):


```{r, Tt2}
entrez_search(db="sra",
              term="Tetrahymena thermophila[ORGN] AND 2013:2015[PDAT]",
              retmax=0)
```

Or recently records for either _T. thermophila_ or it's close relative _T.
borealis_ (using parentheses to make ANDs and ORs explicit).


```{r, Tt3}
entrez_search(db="sra",
              term="(Tetrahymena thermophila[ORGN] OR Tetrahymena borealis[ORGN]) AND 2013:2015[PDAT]",
              retmax=0)
```

The set of search terms avalaliable varies between databases. You can get a list
of avaliable terms or any given data base with `entrez_db_searchable()`

```{r, sra_searchable}
entrez_db_searchable("sra")
```

###Precise queries using MeSH terms

In addition to the seach terms described above, the NCBI allows searches using
[Medical Subject Heading (MeSH)](http://www.ncbi.nlm.nih.gov/mesh) terms. These
terms create a 'controled vocubulary',  and allow users to make very finely
controlled queries of databases.

For instance, if you were interested in reviewing studies on how a class of
anti-malarial drugs called Folic Acid Antagonists work against _Plasmodium vivax_ (a
particular species of malarial parasite), you could use this search:

```{r, mesh}
entrez_search(db   = "pubmed",
              term = "(vivax malaria[MeSH]) AND (folic acid antagonists[MeSH])")
```

The complete database of mesh terms is avaliable in EUtils, so you can search
for specific terms with `entrez_search(db='mesh, term =...)` and learn about the
terms you search finds with the tools described below.

### Advanced counting

As you can see above, the  object returned by `entrez_search()` includes the the
number of records matching a given search. This means you can learn a little
about the composition of, or trends in, the records stored in the NCBI's
databases using only the search utility. For instance, let's track the raise of
the buzzword "connectome" in pubmed, programatically creating  search terms for
the `PDAT` field:

```{r, connectome}
search_year <- function(year, term){
    query <- paste(term, "AND (", year, "[PDAT])")
    entrez_search(db="pubmed", term=query, retmax=0)$count
}

year <- 2008:2014
papers <- sapply(year, search_year, term="Connectome", USE.NAMES=FALSE)

plot(year, as.numeric(papers), type='b', main="The Rise of the Connectome")
```

## Finding cross-references : `entrez_link()`:


One of the strengths of the NCBI databases is the degree to which records of one
type are connected to  other records within the NCBI or to external data
sources. The function `entrez_link()` allows users to uncover these links

###My god, it's full of links

To get an idea of the degree to whih records in the NCBI are cross-linked we can
find all of the other records in NCBI which are linked to the record describing
one gene. To do this we use the `entrez_link` function, providing a gene ID and
specifying that ID comes from the `gene` database by setting `dbfrom` to 'gene'.
To get links from all other databses we set `db` to 'all':

```{r elink0}
all_the_links <- entrez_link(dbfrom='gene', id=351, db='all')
all_the_links
all_the_links$links
```

The resultling list of links takes a format
`[source_database]_[linked_database]` and element in that list is a vector of
IDS. So, to find open-acess papers discussion this gene we could look at links
in PMC:

```{r, elink_pmc}
all_the_links$links$gene_pmc[1:10]
```

Or if were intrested in this genes role in diseases we could find links to OMIM:

```{r, elink_omim}
all_the_links$links$gene_omim

```

###Narrowing our focus

If you know beforehand what sort of links you are looking for, it's a good idea
to use the `db` argument to narrow the focus of your search. Here is an example 
illustrating how to get the transcripts sequences
of corresponding genes with entrez gene id. In NCBI, gene entrez
IDs are stored in the gene database(`dbfrom = gene`) while gene transcript information
is stored in  the nucleotide database(`db = nuccore`), but the good
news is that entries in these two databases are linked, thus, we can
firstly use `entrez_link()` to 'convert' entrez gene id to refseq transcirpt
ID. 

```{r, elink1}
nuc_links <- entrez_link(dbfrom='gene', id=351, db='nuccore')
nuc_links
nuc_links$links
```
The object we get back contains links to the nucleotide database generally, but
also to special subsets of that database like [refseq](http://www.ncbi.nlm.nih.gov/refseq/). 
We can take advantage of this narrower set of links to find IDs that match unique
transcripts from our gene of interest.

```{r, elinik_refseqs}
nuc_links$links$gene_nuccore_refseqrna
```
We can use these ids in calls to `entrez_fetch() or `entrez_summary()` to learn
more about the transcripts they represent. 

###External links

In addition to finding data within the NCBI, `entrez_link` can turn up
connections to external databases. Perhaps the most interesting example is
finding links to the full text of papers in pubmed. For example, when I wrote
this document the first paper linked to our gene of interest above had a pmid of
`25500142`. We can find links to the full text of that paper with `entrez_link` 
by setting the `cmd` argument to 'llinks':

```{r, outlinks}
paper_links <- entrez_link(dbfrom="pubmed", id=25500142, cmd="llinks")
paper_links
```

Instead of a `links` elements, the object returned has a list of `linkouts`.
Each element in that list contains a Url for information aout this paper:

```{r, urls}
paper_links$linkouts
```

The full list of options for the `cmd` argument are given in in-line
documentation (`?entrez_link`).

###Using more than one ID

It is possible to pass more than on ID to `entrez_link()`. By default, doing so
will give you a single elink object containing the complete set of links fo
r _all_ of the IDs that you specified. So, if you were looking for protein IDs
related to specific genes youd could do;

```{r, multi_default}
all_links_together  <- entrez_link(db="protein", dbfrom="gene", id=c("93100", "223646"))
all_links_together
all_links_together$links$gene_protein
```

Although this behaviour might sometimes be useful, it means we've lost track o
which `protein` ID is linked to which `gene` ID. To retain that information we
can set `by_id` to `TRUE`. Doign so gives us a list of elink objects, each once
containing links from a single `gene` ID;

```{r, multi_byid}
all_links_sep  <- entrez_link(db="protein", dbfrom="gene", id=c("93100", "223646"), by_id=TRUE)
all_links_sep
lapply(all_links_sep, function(x) x$links$gene_protein)
```


## Getting summary data: `entrez_summary()`

Having foundt the unique IDs for some records via`entrez_search` or `entrez_link()`, you are
probably going to want to learn something about them. The `Eutils` API has two
ways to get information about a record. `entrez_fetch()` returns 'full' records
in varying formats and `entrez_summary()` returns less information but in
relatively simple format. Very often the summary records have the information
you are afer, so `rentrez` provides functions to parse and summarise summary
recods.


###The summary record

`entrez_summary()` takes a vector of unique IDs for the samples you want to get
summary information from. Let's start by finding out something about the paper
describing [Taxize](https://github.com/ropensci/taxize), using its pubmed ID:


```{r, Summ_1}
taxize_summ <- entrez_summary(db="pubmed", id=24555091)
taxize_summ
```

The object returned by `entrez_summary` behaves like a list, so you can extract
elements using `$`. For instance, we could covert our pubmed ID to another
article ID...

```{r, Summ_2}
taxize_summ$articleids
```
...or see how many times the article has been cited in pubmed-central papers

```{r, Summ_3}
taxize_summ$pmcrefcount
```

###Dealing with many records

If you give `entrez_summary()` a vector with more than one ID you'll get a a
list of summary records back. Let's get those _Plasmodium vivax_ papers we found
in the `entrez_search()` section back, and fetch some summary data on each paper:

```{r, multi_summ}
vivax_search <- entrez_search(db = "pubmed",
                              term = "(vivax malaria[MeSH]) AND (folic acid antagonists[MeSH])")
multi_summs <- entrez_summary(db="pubmed", id=vivax_search$ids)
```

`rentrez` provides a helper function, `extract_from_esummary()` that takes one
or more elements from every summary record in one of these lists. Here is is
working with one...

```{r, multi_summ2}
extract_from_esummary(multi_summs, "fulljournalname")
```
... and several elements:

```{r, multi_summ3}
date_and_cite <- extract_from_esummary(multi_summs, c("pubdate", "pmcrefcount",  "title"))
knitr::kable(head(t(date_and_cite)), row.names=FALSE)
```

##Fetching full records: `entrez_fetch()`

As useful as the summary records are, sometimes they just don't have the
information that you need. If you want a complete representation of a record you
can use `entrez_fetch`, using the argument `rettype` specify for format you'd
like the record in.

###Fetch DNA sequences in fasta format

Let's extend the example given in the `entrez_link()` by dowloading sequences in
the FASTA format. We can start by repeating the steps in the earlier example
to get nucleotide IDs for refseq transcripts for two genes:

```{r, transcript_ids}
gene_ids <- entrenzID <- c(11647, 351)
linked_seq_ids <- entrez_link(dbfrom="gene", id=gene_ids, db="nuccore")
linked_transripts <- linked_seq_ids$links$gene_nuccore_refseqrna
head(linked_transripts)
```

Now we can get our sequnces with `entrez_fetch`, setting `rettype` to "fasta".
(The list of formats avaliable for [each databse is give in this table](http://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/)):

```{r fetch_fasta}
all_recs <- entrez_fetch(db="nuccore", id=linked_transripts, rettype="fasta")
typeof(all_recs)
nchar(all_recs)
```

Congratulations, now you have a really huge character vector! If you want to use
these sequences in some other application you can write them to file:

```r
write(all_recs, file="my_transcripts.fasta")
```

Alternatively, if you want to use these sequences in an r session you write them
to temporary file then read that. In this case I'm using `read.dna()` from the
pylogenetics package ape (but not executing the code block in this vignette, so
you don't have to install that package):

```r
temp <- tempfile()
write(all_recs, temp)
parsed_recs <- ape::read.dna(all_recs, temp)
```

###Fetch a parsed XML document

Most of the NCBI's databases can return records in XML format. In additional to
downloading the text-representation of these files, `entrez_fetch()` can return
ibjects parsed by the `XML` package. As an example, we can check of `taxonomy`
databases' record for the (did I mention they are amazing....) _Tetrahymena
thermophila_. 

```{r, Tt_tax}
Tt <- entrez_search(db="taxonomy", term="(Tetrahymena thermophila[ORGN]) AND Species[RANK]")
tax_rec <- entrez_fetch(db="taxonomy", id=Tt$ids, rettype="xml", parsed=TRUE)
class(tax_rec)
```

The package XML (which you have if you have installed `rentrez`) provides
functions to get information from these files. For relatively simple records
like this one you can use `XML::xmlToList`:

```{r, Tt_list}
tax_list <- XML::xmlToList(tax_rec)
tax_list$Taxon$GeneticCode
```

For more complex records, which generate deeply-nested lists, you can use
[XPath experssions](https://en.wikipedia.org/wiki/XPath) along with the functions 
`XML::xpathApply` or the extraction operator `[` to get specific parts of the
file. In this case we can get the scientific name of each taxon in _T.
thermophila_'s lineage:

```{r, Tt_path}
tax_rec["//LineageEx/Taxon/ScientificName"]
```

As the name suggests, `XML::xpathApply()` can be used to apply a function to
each node. A particularly useful one is `XML::xmlValue` which returns the
content of the node:

```{r, Tt_apply}
XML::xpathApply(tax_rec, "//LineageEx/Taxon/ScientificName", XML::xmlValue)
```
There are a few more complex examples of using `XPath` [on the rentrez wiki](https://github.com/ropensci/rentrez/wiki)

##Using NCBI's Web History features

When you are dealing with very large queries it can be time consuming to pass
long vectors of unique IDs to and from the NCBI. The NCBI provides a 'web
history' feature, that allows users to store a set of IDs on their servers and
refer to them later.  

###Post a set of IDs to the NCBI for later use: `entrez_post()`

If you have a list of many NCBI IDs that you want to use later on, you can post
them to the NCBI's severs. To make a brief example I'm going to post just one
ID, the `omim` identifier for asthma:

```{r, asthma}
upload <- entrez_post(db="omim", id=600807)
upload
```
The NCBI sends you back from information so you can use to refer to IDS you just
uploaded and `rentrez` represents that information as a `web_history` object. 

###Get a `web_history` object from `entrez_search` or `entrez_link()`

In addition to directly uploading ids to the NCBI, you can use the web history
features with `entrez_search` and `entrez_link`. For instance, say you wanted to
find all of the sequences of the widely-studied gene `COI` from snails
(gastropods):

```{r, snail_search}
entrez_search(db="nuccore", term="COI[Gene] AND Gastropoda[ORGN]")
```

That's a lot of sequences! If you really wanted to download all of these it
would be a good idea to save all those IDs to the server by setting
`use_history` to `TRUE` (note you now get a `web_history` object along with your
normal search result):

```{r, snail_history}
snail_coi <- entrez_search(db="nuccore", term="COI[Gene] AND Gastropoda[ORGN]", use_history=TRUE)
snail_coi
snail_coi$web_history
```

Similarily, `entrez_link()` can return `web_history` objects by using the `cmd`
`neighbor_history`. Let's find SNPs associated with asthma (using the `omim` ID
mentioned above):

```{r, asthma_links}
asthma_snps <- entrez_link(dbfrom="omim", db="snp", cmd="neighbor_history", id=600807)
asthma_snps$web_histories
```

As you can see, instead of returning lists of IDs for each linked database (as
it would be default), `entrez_link()` returns a list of web_histories:

###Use a `web_history` object

Once you have those IDs stored on the NCBI's servers, you are going to want to
do something with them. The functions `entrez_fetch()` `entrez_summary()` and
`entrez_link()` can all use `web_history` objects in exactly the same way they
use IDs. 

So, we could repeat the last example (finding SNPs linked to asthma) using our
uploaded id...

```{r, asthma_links_upload}
asthma_snps <- entrez_link(dbfrom="omim", db="snp", cmd="neighbor_history", web_history=upload)
asthma_snps
```

... then summarize each linked SNP using `entrez_summary()`:
                           

```{r, links}
snp_summ <- entrez_summary(db="snp", web_history=asthma_snps$web_histories$omim_snp)
knitr::kable(extract_from_esummary(snp_summ, c("chr", "fxn_class", "global_maf")))
```

If you really wanted to yo could download all those thousands of COI sequences.
When downoading large sets of data, it is a good idea to take advatanage of the
arguments `retmax` and `restart` to split the request up into smaller chunks.
For instance, we could get the first 200 sequences in 50 sequence chunks like
so (this code block is not executed to save time and bandwith):


```r
for( seq_start in seq(1,200,50)){
    recs <- entrez_fetch(db="nuccore", web_history=snail_coi$web_history,
                         rettype="fasta", retmax=50, retstart=seq_start)
    cat(recs, file="snail_coi.fasta", append=TRUE)
    cat(seq_start+49, "sequences downloaded\r")
}
```












